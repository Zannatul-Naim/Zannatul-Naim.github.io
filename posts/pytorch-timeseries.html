<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Getting Started with PyTorch for Time-Series Deep Learning — Zannatul Naim</title>
  <link rel="stylesheet" href="../css/base.css" />
  <link rel="stylesheet" href="../css/blog.css" />
</head>
<body>

<canvas id="starfield"></canvas>

<nav class="nav">
  <a href="../index.html" class="nav__logo">
    <span class="nav__logo-name">Zannatul Naim</span>
    <span class="nav__logo-sub">AI Researcher</span>
  </a>
  <ul class="nav__links">
    <li><a href="../index.html">Home</a></li>
    <li><a href="../about.html">About</a></li>
    <li><a href="../research.html">Research</a></li>
    <li><a href="../skills.html">Skills</a></li>
    <li><a href="../blog.html">Blog</a></li>
    <li><a href="../contact.html">Contact</a></li>
  </ul>
  <button class="nav__hamburger" aria-label="Toggle menu">
    <span></span><span></span><span></span>
  </button>
</nav>
<div class="nav__mobile">
  <a href="../index.html">Home</a>
  <a href="../about.html">About</a>
  <a href="../research.html">Research</a>
  <a href="../skills.html">Skills</a>
  <a href="../blog.html">Blog</a>
  <a href="../contact.html">Contact</a>
</div>

<div class="post-layout">

  <main class="post-main">
    <div class="post-header">
      <a href="../blog.html" class="post-header__back">← Back to Blog</a>
      <div class="post-header__meta">
        <span class="post-header__cat">Tutorial</span>
        <span class="post-header__date">September 2025</span>
        <span class="post-header__readtime">7 min read</span>
      </div>
      <h1 class="post-header__title">
        Getting Started with PyTorch for Time-Series Deep Learning
      </h1>
      <p class="post-header__excerpt">
        A practical guide to building 1D convolutional networks for time-series classification
        in PyTorch, with lessons learned from EEG signal processing. The details that textbooks skip.
      </p>
    </div>

    <div class="post-body">

      <p>
        Time-series classification with deep learning doesn't always get the attention it
        deserves compared to image tasks. But the core principles carry over remarkably well —
        you just need to adapt your mental model from 2D spatial reasoning to 1D temporal reasoning.
      </p>

      <p>
        This guide distills what I learned while building EEG classifiers for my research.
        I'll focus on the practical details that trip people up, not just the architecture diagrams.
      </p>

      <h2>The Core Idea: 1D Convolutions</h2>

      <p>
        In image CNNs, <code>Conv2d</code> kernels slide over height and width dimensions,
        learning spatial patterns. For time-series, <code>Conv1d</code> kernels slide along
        the temporal dimension, learning temporal patterns — oscillations, edges, trends.
      </p>

      <pre><code>import torch
import torch.nn as nn

class TimeSeriesClassifier(nn.Module):
    def __init__(self, n_channels, n_classes, seq_len):
        super().__init__()

        self.features = nn.Sequential(
            # Block 1: capture fast local patterns
            nn.Conv1d(n_channels, 32, kernel_size=7, padding=3),
            nn.BatchNorm1d(32),
            nn.GELU(),
            nn.MaxPool1d(2),
            nn.Dropout(0.25),

            # Block 2: capture slower patterns
            nn.Conv1d(32, 64, kernel_size=15, padding=7),
            nn.BatchNorm1d(64),
            nn.GELU(),
            nn.MaxPool1d(2),
            nn.Dropout(0.25),

            # Block 3: high-level temporal structure
            nn.Conv1d(64, 128, kernel_size=31, padding=15),
            nn.BatchNorm1d(128),
            nn.GELU(),
            nn.AdaptiveAvgPool1d(1),  # Global average pooling
        )

        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128, 64),
            nn.GELU(),
            nn.Dropout(0.5),
            nn.Linear(64, n_classes)
        )

    def forward(self, x):
        # x shape: (batch, channels, time)
        return self.classifier(self.features(x))</code></pre>

      <h2>Lesson 1: Normalization Matters Enormously</h2>

      <p>
        This is the most important lesson from working with EEG data. Raw EEG signals have
        wildly different amplitudes across subjects, sessions, and even channels. If you feed
        raw data to your network, the model will learn amplitude-dependent features that
        don't generalize.
      </p>

      <p>
        Z-score normalize <em>per trial, per channel</em>:
      </p>

      <pre><code>def normalize(x):
    # x: (channels, time)
    mean = x.mean(dim=-1, keepdim=True)
    std  = x.std(dim=-1, keepdim=True) + 1e-8
    return (x - mean) / std</code></pre>

      <p>
        Do this as a preprocessing step, not inside the network. You want your network's
        first layer to receive consistently scaled input regardless of the subject.
      </p>

      <h2>Lesson 2: Kernel Size Is a Design Choice, Not a Hyperparameter</h2>

      <p>
        Kernel size determines what temporal scale of patterns your convolutions can detect.
        For EEG at 256 Hz sampling rate:
      </p>

      <ul>
        <li><strong>Small kernels (3–9 samples)</strong> — ~10–35ms. Capture sharp transient events, spike-like features.</li>
        <li><strong>Medium kernels (15–31 samples)</strong> — ~60–120ms. Capture alpha/beta band oscillatory patterns.</li>
        <li><strong>Large kernels (63–127 samples)</strong> — ~250–500ms. Capture slow drift, low-frequency components.</li>
      </ul>

      <p>
        Multi-scale architectures often win because they process the signal at multiple temporal
        resolutions simultaneously. Inception-style blocks with parallel convolutions of different
        kernel sizes are worth trying.
      </p>

      <h2>Lesson 3: Don't Underestimate Data Augmentation</h2>

      <p>
        When you have 20 subjects × 100 trials × 4 classes, you don't have a lot of data.
        Augmentation is critical, but you need augmentations that preserve class-relevant
        signal characteristics while varying nuisance factors.
      </p>

      <pre><code>def augment(x, label):
    # x: (channels, time)

    # 1. Additive Gaussian noise
    if torch.rand(1) > 0.5:
        x = x + torch.randn_like(x) * 0.05

    # 2. Random temporal shift (circular)
    if torch.rand(1) > 0.5:
        shift = torch.randint(-50, 50, (1,)).item()
        x = torch.roll(x, shift, dims=-1)

    # 3. Channel dropout
    if torch.rand(1) > 0.5:
        n_drop = torch.randint(1, 3, (1,)).item()
        ch_idx = torch.randperm(x.shape[0])[:n_drop]
        x[ch_idx] = 0

    return x, label</code></pre>

      <h2>Lesson 4: Global Average Pooling Over Flattening</h2>

      <p>
        When your input length varies or you want to reduce overfitting in the classification
        head, <code>AdaptiveAvgPool1d(1)</code> (global average pooling) is far better than
        flattening. It forces the network to produce a single feature vector per channel,
        regardless of sequence length, and dramatically reduces parameter count.
      </p>

      <h2>Setting Up Training</h2>

      <pre><code>model     = TimeSeriesClassifier(n_channels=8, n_classes=4, seq_len=256)
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)
criterion = nn.CrossEntropyLoss()

# Training loop
for epoch in range(n_epochs):
    model.train()
    for X_batch, y_batch in train_loader:
        optimizer.zero_grad()
        logits = model(X_batch)
        loss = criterion(logits, y_batch)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()
    scheduler.step()</code></pre>

      <p>
        Note the <strong>gradient clipping</strong> (<code>clip_grad_norm_</code>) —
        essential for time-series models where gradient norms can explode, especially
        with longer sequences.
      </p>

      <hr />

      <p>
        <em>This guide reflects what I learned building classifiers for my UCICS 2026
        paper on subject-independent EEG event recognition. The architecture described
        above is a simplified version of the final model.</em>
      </p>

    </div>

    <div class="post-nav">
      <a href="cross-subject-eeg.html" class="post-nav__item">
        <div class="post-nav__dir">← Previous</div>
        <div class="post-nav__title">Reflections on Cross-Subject EEG Generalization</div>
      </a>
      <div></div>
    </div>

  </main>

  <aside class="post-sidebar">
    <div class="post-sidebar__section">
      <div class="post-sidebar__label">Author</div>
      <div class="post-sidebar__author-name">Zannatul Naim</div>
      <div class="post-sidebar__author-role">AI Researcher · B.Sc. CSE<br>University of Rajshahi</div>
    </div>

    <div class="post-sidebar__section">
      <div class="post-sidebar__label">Table of Contents</div>
      <ul class="post-sidebar__toc">
        <li><a href="#" onclick="return false;">The Core Idea: 1D Convolutions</a></li>
        <li><a href="#" onclick="return false;">Lesson 1: Normalization</a></li>
        <li><a href="#" onclick="return false;">Lesson 2: Kernel Size</a></li>
        <li><a href="#" onclick="return false;">Lesson 3: Data Augmentation</a></li>
        <li><a href="#" onclick="return false;">Lesson 4: Global Avg Pooling</a></li>
        <li><a href="#" onclick="return false;">Setting Up Training</a></li>
      </ul>
    </div>

    <div class="post-sidebar__section">
      <div class="post-sidebar__label">Tags</div>
      <div style="display:flex;flex-wrap:wrap;gap:0.4rem;">
        <span style="font-family:'IBM Plex Mono',monospace;font-size:0.6rem;padding:0.25rem 0.6rem;border:1px solid var(--border);border-radius:2px;color:var(--muted);">PyTorch</span>
        <span style="font-family:'IBM Plex Mono',monospace;font-size:0.6rem;padding:0.25rem 0.6rem;border:1px solid var(--border);border-radius:2px;color:var(--muted);">Tutorial</span>
        <span style="font-family:'IBM Plex Mono',monospace;font-size:0.6rem;padding:0.25rem 0.6rem;border:1px solid var(--border);border-radius:2px;color:var(--muted);">1D CNN</span>
        <span style="font-family:'IBM Plex Mono',monospace;font-size:0.6rem;padding:0.25rem 0.6rem;border:1px solid var(--border);border-radius:2px;color:var(--muted);">EEG</span>
        <span style="font-family:'IBM Plex Mono',monospace;font-size:0.6rem;padding:0.25rem 0.6rem;border:1px solid var(--border);border-radius:2px;color:var(--muted);">Time-Series</span>
      </div>
    </div>
  </aside>

</div>

<footer class="footer" style="margin-top:4rem;">
  <span class="footer__left">© 2025 Zannatul Naim</span>
  <span class="footer__center">Built with curiosity & precision</span>
  <span class="footer__right">Rajshahi, Bangladesh</span>
</footer>

<script src="../js/main.js"></script>
</body>
</html>
