<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Understanding YOLOv1: A Beginner's Guide to Object Detection</title>
    <!-- MathJax for rendering LaTeX equations -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #f4f4f9;
            color: #333;
        }
        header {
            background: linear-gradient(90deg, #2c3e50, #3498db);
            color: white;
            text-align: center;
            padding: 2em 0;
        }
        header h1 {
            margin: 0;
            font-size: 2.5em;
        }
        .container {
            max-width: 900px;
            margin: 2em auto;
            padding: 0 20px;
        }
        .section {
            margin-bottom: 2em;
            background: white;
            padding: 1.5em;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h2 {
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 0.3em;
        }
        p {
            margin: 1em 0;
        }
        .image-container {
            text-align: center;
            margin: 1.5em 0;
        }
        .image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.2);
        }
        .equation {
            background: #f9f9f9;
            padding: 1em;
            border-left: 4px solid #3498db;
            margin: 1em 0;
            font-family: 'Times New Roman', Times, serif;
            font-size: 1.2em;
            text-align: center;
        }
        footer {
            text-align: center;
            padding: 1em 0;
            background: #2c3e50;
            color: white;
            position: relative;
            bottom: 0;
            width: 100%;
        }
        @media (max-width: 600px) {
            header h1 {
                font-size: 1.8em;
            }
            .container {
                padding: 0 10px;
            }
        }

        nav {
            background: linear-gradient(90deg, #2c3e50, #3498db);
            position: fixed;
            top: 0;
            right: 0;
            width: auto;
            z-index: 1000;
            padding: 0.5em 1em;
        }
        nav ul {
            list-style: none;
            margin: 0;
            padding: 0.5em;
            display: flex;
            justify-content: flex-end;
        }
        nav ul li {
            margin: 0 1em;
        }
        nav ul li a {
            color: white;
            text-decoration: none;
            font-size: 1.1em;
            transition: color 0.3s;
        }
        nav ul li a:hover {
            color: #f1c40f;
        }
        @media (max-width: 600px) {
            nav ul {
                flex-direction: column;
                align-items: flex-end;
            }
            nav ul li {
                margin: 0.5em 0;
            }
        }
    </style>
</head>
<body>

    <nav>
        <ul>
            <li><a href="./../../index.html">Home</a></li>
            <li><a href="../blog-page.html">Blogs</a></li>
            <!-- <li><a href="yolo-v1-blog.html">YOLOv1</a></li>
            <li><a href="cnn-blog.html">CNN</a></li> -->
        </ul>
    </nav>

    <header>
        <h1>Understanding YOLOv1: A Beginner's Guide to Object Detection</h1>
    </header>
    <div class="container">
        <div class="section">
            <h2>What is YOLO?</h2>
            <p>YOLO, which stands for "You Only Look Once," is a popular object detection model that revolutionized how computers identify and locate objects in images. Introduced in 2015 by Joseph Redmon and colleagues, YOLOv1 was the first version of this model, designed to be fast and efficient by processing an entire image in a single pass, unlike earlier methods that scanned images multiple times.</p>
            <p>For beginners, think of YOLOv1 as a smart camera that can look at a picture and instantly tell you what objects are in it (e.g., a dog, a car) and where they are located, all in one quick step.</p>
            <div class="image-container">
                <img src="https://iq.opengenus.org/content/images/2019/07/image_5.png" alt="YOLO Object Detection Example">
                <p><em>Figure 1: YOLO detecting objects in an image, identifying and localizing objects like cars and bi-cycle and dog. <a href="https://iq.opengenus.org/content/images/2019/07/image_5.png">reference</a></em></p>
            </div>
        </div>

        <div class="section">
            <h2>How Does YOLOv1 Work?</h2>
            <p>YOLOv1 treats object detection as a single regression problem. Instead of analyzing an image piece by piece, it divides the image into a grid and predicts:</p>
            <ul>
                <li><strong>Bounding boxes:</strong> Rectangular boxes around detected objects, defined by coordinates \((x, y, w, h)\), where \((x, y)\) is the center, and \(w\) and \(h\) are the width and height.</li>
                <li><strong>Class probabilities:</strong> The likelihood that an object belongs to a specific class (e.g., "dog" or "cat").</li>
                <li><strong>Confidence scores:</strong> How confident the model is that a box contains an object and how accurate the box is.</li>
            </ul>
            <p>The image is divided into an \(S \times S\) grid (in YOLOv1, \(S = 7\)). Each grid cell predicts \(B\) bounding boxes (typically \(B = 2\)) and their confidence scores, along with class probabilities for \(C\) classes. The output is a tensor of shape \(S \times S \times (B \cdot 5 + C)\), where 5 accounts for the box coordinates and confidence score.</p>
            <div class="equation">
                \( \text{Output Tensor} = S \times S \times (B \cdot 5 + C) \)
                <p><em>Equation 1: YOLOv1 output tensor structure, where \(S\) is the grid size, \(B\) is the number of bounding boxes per cell, and \(C\) is the number of classes.</em></p>
            </div>
        </div>

        <div class="section">
            <h2>YOLOv1 Architecture</h2>
            <p>The YOLOv1 model is built using a convolutional neural network (CNN) inspired by GoogLeNet. It has 24 convolutional layers for feature extraction, followed by 2 fully connected layers to predict bounding boxes and class probabilities. The input image is resized to \(448 \times 448\) pixels, and the network processes it to produce predictions in one forward pass.</p>
            <div class="image-container">
                <img src="https://www.researchgate.net/profile/An-Cong/publication/337462114/figure/fig4/AS:11431281095260387@1667830341543/The-YOLO-architecture-13.ppm" alt="YOLOv1 Architecture">
                <p><em>Figure 2: YOLOv1 architecture, showing convolutional layers followed by fully connected layers for object detection.</em> <a href="https://www.researchgate.net/profile/An-Cong/publication/337462114/figure/fig4/AS:11431281095260387@1667830341543/The-YOLO-architecture-13.ppm">reference</a></p>
            </div>
            <p>The architecture can be summarized as:</p>
            <ul>
                <li><strong>Convolutional Layers:</strong> Extract features like edges, shapes, and textures from the image.</li>
                <li><strong>Max-Pooling Layers:</strong> Reduce spatial dimensions to make the model faster and less prone to overfitting.</li>
                <li><strong>Fully Connected Layers:</strong> Combine features to predict bounding boxes and class probabilities.</li>
            </ul>
        </div>

        <div class="section">
            <h2>Loss Function in YOLOv1</h2>
            <p>YOLOv1 uses a custom loss function to optimize its predictions. The loss function balances three components:</p>
            <ul>
                <li><strong>Localization Loss:</strong> Penalizes errors in bounding box coordinates (\(x, y, w, h\)).</li>
                <li><strong>Confidence Loss:</strong> Ensures accurate confidence scores for boxes with and without objects.</li>
                <li><strong>Classification Loss:</strong> Penalizes incorrect class predictions.</li>
            </ul>
            <p>The loss function can be expressed as:</p>
            <div class="equation">
                \( \text{Loss} = \lambda_{\text{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{ij}^{\text{obj}} \left[ (x_i - \hat{x}_i)^2 + (y_i - \hat{y}_i)^2 + (w_i - \hat{w}_i)^2 + (h_i - \hat{h}_i)^2 \right] + \dots \)
                <p><em>Equation 2: Simplified YOLOv1 loss function (localization component), where \(\lambda_{\text{coord}}\) weights the localization loss, and \(\mathbb{1}_{ij}^{\text{obj}}\) indicates if an object exists in the box.</em></p>
            </div>
            <p>This loss ensures the model learns to predict accurate boxes and classes while being computationally efficient.</p>
        </div>

        <div class="section">
            <h2>Advantages and Limitations of YOLOv1</h2>
            <p><strong>Advantages:</strong></p>
            <ul>
                <li>Fast: Processes images in a single pass, making it real-time capable.</li>
                <li>Global Context: Considers the entire image, reducing false positives.</li>
                <li>Simple: Easy to implement and understand compared to multi-stage detectors.</li>
            </ul>
            <p><strong>Limitations:</strong></p>
            <ul>
                <li>Struggles with small objects due to the coarse \(7 \times 7\) grid.</li>
                <li>Localization errors: Bounding box predictions can be less accurate than other models.</li>
                <li>Limited boxes per grid cell: Only predicts two boxes per cell, which can miss overlapping objects.</li>
            </ul>
            <!-- <div class="image-container">
                <img src="https://via.placeholder.com/600x300.png?text=YOLOv1+Limitations" alt="YOLOv1 Limitations">
                <p><em>Figure 3: Example of YOLOv1 struggling with small or overlapping objects.</em></p>
            </div> -->
        </div>

        <div class="section">
            <h2>Conclusion</h2>
            <p>YOLOv1 is a groundbreaking model that made object detection fast and accessible. While newer versions like YOLOv8 have improved accuracy and capabilities, YOLOv1 remains a great starting point for beginners due to its simplicity. Understanding its grid-based approach and CNN architecture lays the foundation for exploring more advanced object detection models.</p>
            <!-- <div class="image-container">
                <img src="https://via.placeholder.com/600x300.png?text=Future+of+Object+Detection" alt="Future of Object Detection">
                <p><em>Figure 4: The evolution of object detection from YOLOv1 to modern models.</em></p>
            </div> -->
        </div>
    </div>
    <!-- <footer>
        <p>© 2025 Blog. All rights reserved.</p>
    </footer> -->
</body>
</html>